{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alekseyl\\Envs\\absa\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from importlib import reload\n",
    "from utils import *\n",
    "import test\n",
    "import acd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from jupyterthemes import jtplot\n",
    "# jtplot.style()  # development\n",
    "jtplot.reset()  # production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading real w2v...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "w2v = load_w2v()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "-- ACD:\n",
      "Loading dataset...\n",
      "Training...\n",
      "Evaluating...\n",
      "F1: 0.7775524002704529\n"
     ]
    }
   ],
   "source": [
    "reload(acd)\n",
    "acd_ = acd.ACD(w2v)\n",
    "acd_.train_acd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import polarity\n",
    "reload(polarity)\n",
    "pd_ = polarity.PD(w2v, acd_)\n",
    "# datasets = pd_.load_grid_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import polarity\n",
    "reload(polarity)\n",
    "pd_ = polarity.PD(w2v, acd_)\n",
    "# pd_.grid_search_pd(datasets, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- PD:\n",
      "Loading tokenizer...\n",
      "Loading stemmer...\n",
      "Loading parser...\n",
      "Loading datasets...\n",
      "Core NLP Parser preprocessing result pickled\n",
      "get_pd_ds progress: 0/1708\n",
      "get_pd_ds progress: 100/1708\n",
      "get_pd_ds progress: 200/1708\n",
      "get_pd_ds progress: 300/1708\n",
      "get_pd_ds progress: 400/1708\n",
      "get_pd_ds progress: 500/1708\n",
      "get_pd_ds progress: 600/1708\n",
      "get_pd_ds progress: 700/1708\n",
      "get_pd_ds progress: 800/1708\n",
      "get_pd_ds progress: 900/1708\n",
      "get_pd_ds progress: 1000/1708\n",
      "get_pd_ds progress: 1100/1708\n",
      "get_pd_ds progress: 1200/1708\n",
      "get_pd_ds progress: 1300/1708\n",
      "get_pd_ds progress: 1400/1708\n",
      "get_pd_ds progress: 1500/1708\n",
      "get_pd_ds progress: 1600/1708\n",
      "get_pd_ds progress: 1700/1708\n",
      "Core NLP Parser preprocessing result pickled\n",
      "get_pd_ds progress: 0/587\n",
      "get_pd_ds progress: 100/587\n",
      "get_pd_ds progress: 200/587\n",
      "get_pd_ds progress: 300/587\n",
      "get_pd_ds progress: 400/587\n",
      "get_pd_ds progress: 500/587\n"
     ]
    }
   ],
   "source": [
    "import polarity\n",
    "reload(polarity)\n",
    "pd_ = polarity.PD(w2v, acd_)\n",
    "data = pd_.prepare_data(pd_.get_pd_features_map_tree_distance, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- PD:\n",
      "Loading tokenizer...\n",
      "Loading stemmer...\n",
      "Loading parser...\n",
      "Loading datasets...\n",
      "Core NLP Parser preprocessing result pickled\n",
      "get_pd_ds progress: 0/1708\n",
      "get_pd_ds progress: 100/1708\n",
      "get_pd_ds progress: 200/1708\n",
      "get_pd_ds progress: 300/1708\n",
      "get_pd_ds progress: 400/1708\n",
      "get_pd_ds progress: 500/1708\n",
      "get_pd_ds progress: 600/1708\n",
      "get_pd_ds progress: 700/1708\n",
      "get_pd_ds progress: 800/1708\n",
      "get_pd_ds progress: 900/1708\n",
      "get_pd_ds progress: 1000/1708\n",
      "get_pd_ds progress: 1100/1708\n",
      "get_pd_ds progress: 1200/1708\n",
      "get_pd_ds progress: 1300/1708\n",
      "get_pd_ds progress: 1400/1708\n",
      "get_pd_ds progress: 1500/1708\n",
      "get_pd_ds progress: 1600/1708\n",
      "get_pd_ds progress: 1700/1708\n",
      "Core NLP Parser preprocessing result pickled\n",
      "get_pd_ds progress: 0/587\n",
      "get_pd_ds progress: 100/587\n",
      "get_pd_ds progress: 200/587\n",
      "get_pd_ds progress: 300/587\n",
      "get_pd_ds progress: 400/587\n",
      "get_pd_ds progress: 500/587\n",
      "Train on 2524 samples, validate on 842 samples\n",
      "Epoch 1/8\n",
      "2524/2524 [==============================] - 3s - loss: 0.8360 - acc: 0.6743 - val_loss: 0.7012 - val_acc: 0.6675\n",
      "Epoch 2/8\n",
      "2524/2524 [==============================] - 2s - loss: 0.6607 - acc: 0.6949 - val_loss: 0.5905 - val_acc: 0.7209\n",
      "Epoch 3/8\n",
      "2524/2524 [==============================] - 2s - loss: 0.5735 - acc: 0.7698 - val_loss: 0.5182 - val_acc: 0.8052\n",
      "Epoch 4/8\n",
      "2524/2524 [==============================] - 2s - loss: 0.5125 - acc: 0.8055 - val_loss: 0.5075 - val_acc: 0.8195\n",
      "Epoch 5/8\n",
      "2524/2524 [==============================] - 2s - loss: 0.4647 - acc: 0.8284 - val_loss: 0.4902 - val_acc: 0.7933\n",
      "Epoch 6/8\n",
      "2524/2524 [==============================] - 2s - loss: 0.4206 - acc: 0.8487 - val_loss: 0.4506 - val_acc: 0.8420\n",
      "Epoch 7/8\n",
      "2524/2524 [==============================] - 2s - loss: 0.3978 - acc: 0.8542 - val_loss: 0.4430 - val_acc: 0.8432\n",
      "Epoch 8/8\n",
      "2524/2524 [==============================] - 2s - loss: 0.3693 - acc: 0.8697 - val_loss: 0.4430 - val_acc: 0.8539\n",
      "Max val_acc: 0.8539192308439495 (epoch: 8)\n",
      "Shape: (2524, 50)\n",
      "predictions: (842,)\n",
      "actuals: (842,)\n",
      "predictions: (842,)\n",
      "actuals: (842,)\n",
      "predictions: (842,)\n",
      "actuals: (842,)\n",
      "Scores: [0.85154394299287406, 0.86460807600950118, 0.87410926365795727]\n"
     ]
    }
   ],
   "source": [
    "import polarity\n",
    "reload(polarity)\n",
    "pd_ = polarity.PD(w2v, acd_)\n",
    "pd_.train_pd_keras_both_svm(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "absa",
   "language": "python",
   "name": "absa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
