{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "from utils import *\n",
    "import test\n",
    "import polarity\n",
    "import acd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v = load_w2v()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(acd)\n",
    "acd_ = acd.ACD(w2v)\n",
    "acd_.train_acd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- PD:\n",
      "Loading tokenizer...\n",
      "Loading stemmer...\n",
      "Loading parser...\n",
      "Loading dataset...\n",
      "Core NLP Parser preprocessing result pickled\n",
      "get_pd_ds progress: 0/1708\n",
      "get_pd_ds progress: 100/1708\n",
      "get_pd_ds progress: 200/1708\n",
      "get_pd_ds progress: 300/1708\n",
      "get_pd_ds progress: 400/1708\n",
      "get_pd_ds progress: 500/1708\n",
      "get_pd_ds progress: 600/1708\n",
      "get_pd_ds progress: 700/1708\n",
      "get_pd_ds progress: 800/1708\n",
      "get_pd_ds progress: 900/1708\n",
      "get_pd_ds progress: 1000/1708\n",
      "get_pd_ds progress: 1100/1708\n",
      "get_pd_ds progress: 1200/1708\n",
      "get_pd_ds progress: 1300/1708\n",
      "get_pd_ds progress: 1400/1708\n",
      "get_pd_ds progress: 1500/1708\n",
      "get_pd_ds progress: 1600/1708\n",
      "get_pd_ds progress: 1700/1708\n"
     ]
    }
   ],
   "source": [
    "reload(polarity)\n",
    "pd = polarity.PD(w2v, acd_)\n",
    "data = pd.prepare_data(pd.get_pd_features_map_tree_distance, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2005 samples, validate on 502 samples\n",
      "Epoch 1/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.7653 - acc: 0.7152 - val_loss: 0.9713 - val_acc: 0.4243\n",
      "Epoch 2/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.6289 - acc: 0.7232 - val_loss: 0.9823 - val_acc: 0.4243\n",
      "Epoch 3/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.5748 - acc: 0.7397 - val_loss: 0.8166 - val_acc: 0.4940\n",
      "Epoch 4/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.5166 - acc: 0.7900 - val_loss: 0.6693 - val_acc: 0.7371\n",
      "Epoch 5/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.4784 - acc: 0.8180 - val_loss: 0.6584 - val_acc: 0.7271\n",
      "Epoch 6/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.4427 - acc: 0.8389 - val_loss: 0.8035 - val_acc: 0.5717\n",
      "Epoch 7/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.4181 - acc: 0.8514 - val_loss: 0.6700 - val_acc: 0.6773\n",
      "Epoch 8/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.3993 - acc: 0.8549 - val_loss: 0.6497 - val_acc: 0.7072\n",
      "Epoch 9/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.3765 - acc: 0.8618 - val_loss: 0.7107 - val_acc: 0.6494\n",
      "Epoch 10/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.3643 - acc: 0.8678 - val_loss: 0.6243 - val_acc: 0.7430\n",
      "Epoch 11/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.3443 - acc: 0.8718 - val_loss: 0.5993 - val_acc: 0.7749\n",
      "Epoch 12/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.3352 - acc: 0.8813 - val_loss: 0.6803 - val_acc: 0.6733\n",
      "Epoch 13/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.3217 - acc: 0.8878 - val_loss: 0.6003 - val_acc: 0.7709\n",
      "Epoch 14/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.3137 - acc: 0.8843 - val_loss: 0.5683 - val_acc: 0.8068\n",
      "Epoch 15/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.2947 - acc: 0.8878 - val_loss: 0.6336 - val_acc: 0.7371\n",
      "Epoch 16/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.2875 - acc: 0.8968 - val_loss: 0.5952 - val_acc: 0.7689\n",
      "Epoch 17/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.2815 - acc: 0.8913 - val_loss: 0.6232 - val_acc: 0.7470\n",
      "Epoch 18/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.2708 - acc: 0.9037 - val_loss: 0.6775 - val_acc: 0.7012\n",
      "Epoch 19/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.2641 - acc: 0.9042 - val_loss: 0.6368 - val_acc: 0.7351\n",
      "Epoch 20/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.2541 - acc: 0.9117 - val_loss: 0.5781 - val_acc: 0.7869\n",
      "Epoch 21/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.2510 - acc: 0.9112 - val_loss: 0.6211 - val_acc: 0.7490\n",
      "Epoch 22/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.2416 - acc: 0.9102 - val_loss: 0.5709 - val_acc: 0.7988\n",
      "Epoch 23/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.2365 - acc: 0.9072 - val_loss: 0.6478 - val_acc: 0.7390\n",
      "Epoch 24/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.2232 - acc: 0.9177 - val_loss: 0.6479 - val_acc: 0.7351\n",
      "Epoch 25/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.2220 - acc: 0.9192 - val_loss: 0.6721 - val_acc: 0.7151\n",
      "Epoch 26/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.2154 - acc: 0.9237 - val_loss: 0.7285 - val_acc: 0.6773\n",
      "Epoch 27/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.2107 - acc: 0.9267 - val_loss: 0.6843 - val_acc: 0.7072\n",
      "Epoch 28/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.2052 - acc: 0.9282 - val_loss: 0.7435 - val_acc: 0.6713\n",
      "Epoch 29/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.2051 - acc: 0.9222 - val_loss: 0.5661 - val_acc: 0.8008\n",
      "Epoch 30/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1941 - acc: 0.9307 - val_loss: 0.6004 - val_acc: 0.7789\n",
      "Epoch 31/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1907 - acc: 0.9327 - val_loss: 0.7019 - val_acc: 0.7052\n",
      "Epoch 32/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1869 - acc: 0.9332 - val_loss: 0.6675 - val_acc: 0.7371\n",
      "Epoch 33/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1830 - acc: 0.9287 - val_loss: 0.6754 - val_acc: 0.7211\n",
      "Epoch 34/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1825 - acc: 0.9327 - val_loss: 0.6184 - val_acc: 0.7649\n",
      "Epoch 35/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1726 - acc: 0.9357 - val_loss: 0.6378 - val_acc: 0.7550\n",
      "Epoch 36/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1718 - acc: 0.9357 - val_loss: 0.6744 - val_acc: 0.7291\n",
      "Epoch 37/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1675 - acc: 0.9411 - val_loss: 0.6417 - val_acc: 0.7550\n",
      "Epoch 38/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1585 - acc: 0.9426 - val_loss: 0.6652 - val_acc: 0.7390\n",
      "Epoch 39/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1612 - acc: 0.9441 - val_loss: 0.7459 - val_acc: 0.6912\n",
      "Epoch 40/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1591 - acc: 0.9431 - val_loss: 0.6964 - val_acc: 0.7191\n",
      "Epoch 41/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1545 - acc: 0.9421 - val_loss: 0.6537 - val_acc: 0.7450\n",
      "Epoch 42/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1523 - acc: 0.9461 - val_loss: 0.6223 - val_acc: 0.7709\n",
      "Epoch 43/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1505 - acc: 0.9367 - val_loss: 0.7052 - val_acc: 0.7211\n",
      "Epoch 44/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1498 - acc: 0.9461 - val_loss: 0.6817 - val_acc: 0.7371\n",
      "Epoch 45/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1411 - acc: 0.9451 - val_loss: 0.5918 - val_acc: 0.7849\n",
      "Epoch 46/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1408 - acc: 0.9486 - val_loss: 0.7024 - val_acc: 0.7231\n",
      "Epoch 47/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1403 - acc: 0.9486 - val_loss: 0.6610 - val_acc: 0.7550\n",
      "Epoch 48/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1383 - acc: 0.9476 - val_loss: 0.7371 - val_acc: 0.7012\n",
      "Epoch 49/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1344 - acc: 0.9511 - val_loss: 0.7358 - val_acc: 0.7131\n",
      "Epoch 50/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1304 - acc: 0.9511 - val_loss: 0.6895 - val_acc: 0.7371\n",
      "Epoch 51/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1287 - acc: 0.9511 - val_loss: 0.6153 - val_acc: 0.7789\n",
      "Epoch 52/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1268 - acc: 0.9511 - val_loss: 0.7139 - val_acc: 0.7251\n",
      "Epoch 53/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1299 - acc: 0.9516 - val_loss: 0.6340 - val_acc: 0.7610\n",
      "Epoch 54/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1238 - acc: 0.9461 - val_loss: 0.7547 - val_acc: 0.7052\n",
      "Epoch 55/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1230 - acc: 0.9531 - val_loss: 0.7301 - val_acc: 0.7211\n",
      "Epoch 56/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1255 - acc: 0.9511 - val_loss: 0.7122 - val_acc: 0.7271\n",
      "Epoch 57/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1186 - acc: 0.9576 - val_loss: 0.7326 - val_acc: 0.7231\n",
      "Epoch 58/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1204 - acc: 0.9561 - val_loss: 0.6796 - val_acc: 0.7510\n",
      "Epoch 59/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1199 - acc: 0.9521 - val_loss: 0.6675 - val_acc: 0.7530\n",
      "Epoch 60/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1196 - acc: 0.9586 - val_loss: 0.7228 - val_acc: 0.7271\n",
      "Epoch 61/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1171 - acc: 0.9536 - val_loss: 0.6398 - val_acc: 0.7709\n",
      "Epoch 62/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1153 - acc: 0.9526 - val_loss: 0.6947 - val_acc: 0.7430\n",
      "Epoch 63/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1175 - acc: 0.9541 - val_loss: 0.7111 - val_acc: 0.7410\n",
      "Epoch 64/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1101 - acc: 0.9546 - val_loss: 0.6799 - val_acc: 0.7550\n",
      "Epoch 65/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1100 - acc: 0.9571 - val_loss: 0.6824 - val_acc: 0.7550\n",
      "Epoch 66/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1169 - acc: 0.9526 - val_loss: 0.6784 - val_acc: 0.7590\n",
      "Epoch 67/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1133 - acc: 0.9546 - val_loss: 0.6949 - val_acc: 0.7510\n",
      "Epoch 68/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1036 - acc: 0.9656 - val_loss: 0.6959 - val_acc: 0.7510\n",
      "Epoch 69/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1078 - acc: 0.9601 - val_loss: 0.7283 - val_acc: 0.7331\n",
      "Epoch 70/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1059 - acc: 0.9556 - val_loss: 0.8596 - val_acc: 0.6873\n",
      "Epoch 71/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1118 - acc: 0.9516 - val_loss: 0.7194 - val_acc: 0.7390\n",
      "Epoch 72/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1040 - acc: 0.9561 - val_loss: 0.6831 - val_acc: 0.7530\n",
      "Epoch 73/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1055 - acc: 0.9596 - val_loss: 0.6227 - val_acc: 0.7888\n",
      "Epoch 74/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1042 - acc: 0.9591 - val_loss: 0.6500 - val_acc: 0.7769\n",
      "Epoch 75/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1003 - acc: 0.9621 - val_loss: 0.8118 - val_acc: 0.7032\n",
      "Epoch 76/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1004 - acc: 0.9586 - val_loss: 0.6871 - val_acc: 0.7530\n",
      "Epoch 77/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1047 - acc: 0.9576 - val_loss: 0.7151 - val_acc: 0.7470\n",
      "Epoch 78/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1006 - acc: 0.9576 - val_loss: 0.7256 - val_acc: 0.7450\n",
      "Epoch 79/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.1014 - acc: 0.9601 - val_loss: 0.7856 - val_acc: 0.7171\n",
      "Epoch 80/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0977 - acc: 0.9606 - val_loss: 0.7601 - val_acc: 0.7191\n",
      "Epoch 81/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0976 - acc: 0.9591 - val_loss: 0.7105 - val_acc: 0.7510\n",
      "Epoch 82/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0944 - acc: 0.9626 - val_loss: 0.8072 - val_acc: 0.7131\n",
      "Epoch 83/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0971 - acc: 0.9566 - val_loss: 0.7368 - val_acc: 0.7470\n",
      "Epoch 84/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0911 - acc: 0.9626 - val_loss: 0.6891 - val_acc: 0.7570\n",
      "Epoch 85/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0954 - acc: 0.9621 - val_loss: 0.8956 - val_acc: 0.6813\n",
      "Epoch 86/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0964 - acc: 0.9586 - val_loss: 0.7300 - val_acc: 0.7510\n",
      "Epoch 87/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0922 - acc: 0.9636 - val_loss: 0.7619 - val_acc: 0.7371\n",
      "Epoch 88/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0876 - acc: 0.9656 - val_loss: 0.8202 - val_acc: 0.7171\n",
      "Epoch 89/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0993 - acc: 0.9606 - val_loss: 0.8220 - val_acc: 0.7151\n",
      "Epoch 90/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0981 - acc: 0.9561 - val_loss: 0.7291 - val_acc: 0.7470\n",
      "Epoch 91/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0939 - acc: 0.9606 - val_loss: 0.7944 - val_acc: 0.7231\n",
      "Epoch 92/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0988 - acc: 0.9601 - val_loss: 0.7114 - val_acc: 0.7490\n",
      "Epoch 93/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0923 - acc: 0.9606 - val_loss: 0.7187 - val_acc: 0.7550\n",
      "Epoch 94/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0985 - acc: 0.9551 - val_loss: 0.7494 - val_acc: 0.7371\n",
      "Epoch 95/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0957 - acc: 0.9636 - val_loss: 0.7259 - val_acc: 0.7550\n",
      "Epoch 96/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0987 - acc: 0.9571 - val_loss: 0.6921 - val_acc: 0.7709\n",
      "Epoch 97/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0995 - acc: 0.9526 - val_loss: 0.7389 - val_acc: 0.7510\n",
      "Epoch 98/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0944 - acc: 0.9616 - val_loss: 0.7087 - val_acc: 0.7550\n",
      "Epoch 99/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0910 - acc: 0.9621 - val_loss: 0.7679 - val_acc: 0.7331\n",
      "Epoch 100/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0904 - acc: 0.9606 - val_loss: 0.7603 - val_acc: 0.7390\n",
      "Epoch 101/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0958 - acc: 0.9586 - val_loss: 0.6559 - val_acc: 0.7928\n",
      "Epoch 102/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0869 - acc: 0.9611 - val_loss: 0.6825 - val_acc: 0.7809\n",
      "Epoch 103/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0867 - acc: 0.9591 - val_loss: 0.8150 - val_acc: 0.7131\n",
      "Epoch 104/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0888 - acc: 0.9626 - val_loss: 0.7775 - val_acc: 0.7311\n",
      "Epoch 105/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0912 - acc: 0.9636 - val_loss: 0.8532 - val_acc: 0.6972\n",
      "Epoch 106/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0917 - acc: 0.9606 - val_loss: 0.7515 - val_acc: 0.7510\n",
      "Epoch 107/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0898 - acc: 0.9631 - val_loss: 0.7391 - val_acc: 0.7530\n",
      "Epoch 108/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0854 - acc: 0.9601 - val_loss: 0.7528 - val_acc: 0.7470\n",
      "Epoch 109/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0882 - acc: 0.9641 - val_loss: 0.6939 - val_acc: 0.7729\n",
      "Epoch 110/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0880 - acc: 0.9606 - val_loss: 0.7085 - val_acc: 0.7649\n",
      "Epoch 111/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0890 - acc: 0.9626 - val_loss: 0.6948 - val_acc: 0.7769\n",
      "Epoch 112/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0908 - acc: 0.9601 - val_loss: 0.7552 - val_acc: 0.7510\n",
      "Epoch 113/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0905 - acc: 0.9621 - val_loss: 0.8575 - val_acc: 0.7092\n",
      "Epoch 114/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0903 - acc: 0.9551 - val_loss: 0.6867 - val_acc: 0.7789\n",
      "Epoch 115/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0900 - acc: 0.9586 - val_loss: 0.7667 - val_acc: 0.7371\n",
      "Epoch 116/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0806 - acc: 0.9656 - val_loss: 0.7586 - val_acc: 0.7430\n",
      "Epoch 117/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0843 - acc: 0.9631 - val_loss: 0.8005 - val_acc: 0.7311\n",
      "Epoch 118/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0885 - acc: 0.9606 - val_loss: 0.7342 - val_acc: 0.7649\n",
      "Epoch 119/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0891 - acc: 0.9596 - val_loss: 0.8049 - val_acc: 0.7331\n",
      "Epoch 120/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0849 - acc: 0.9591 - val_loss: 0.7759 - val_acc: 0.7430\n",
      "Epoch 121/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0918 - acc: 0.9581 - val_loss: 0.7666 - val_acc: 0.7390\n",
      "Epoch 122/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0905 - acc: 0.9631 - val_loss: 0.7474 - val_acc: 0.7610\n",
      "Epoch 123/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0880 - acc: 0.9611 - val_loss: 0.7977 - val_acc: 0.7371\n",
      "Epoch 124/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0843 - acc: 0.9661 - val_loss: 0.8000 - val_acc: 0.7351\n",
      "Epoch 125/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0950 - acc: 0.9596 - val_loss: 0.8059 - val_acc: 0.7331\n",
      "Epoch 126/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0911 - acc: 0.9571 - val_loss: 0.6727 - val_acc: 0.7888\n",
      "Epoch 127/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0901 - acc: 0.9621 - val_loss: 0.7835 - val_acc: 0.7390\n",
      "Epoch 128/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0884 - acc: 0.9606 - val_loss: 0.7706 - val_acc: 0.7410\n",
      "Epoch 129/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0784 - acc: 0.9661 - val_loss: 0.7186 - val_acc: 0.7709\n",
      "Epoch 130/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0759 - acc: 0.9661 - val_loss: 0.7559 - val_acc: 0.7689\n",
      "Epoch 131/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0861 - acc: 0.9621 - val_loss: 0.8324 - val_acc: 0.7151\n",
      "Epoch 132/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0886 - acc: 0.9626 - val_loss: 0.7598 - val_acc: 0.7570\n",
      "Epoch 133/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0778 - acc: 0.9666 - val_loss: 0.7438 - val_acc: 0.7570\n",
      "Epoch 134/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0804 - acc: 0.9666 - val_loss: 0.6982 - val_acc: 0.7928\n",
      "Epoch 135/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0813 - acc: 0.9616 - val_loss: 0.8280 - val_acc: 0.7271\n",
      "Epoch 136/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0873 - acc: 0.9571 - val_loss: 0.8370 - val_acc: 0.7131\n",
      "Epoch 137/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0840 - acc: 0.9646 - val_loss: 0.7612 - val_acc: 0.7570\n",
      "Epoch 138/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0862 - acc: 0.9616 - val_loss: 0.7153 - val_acc: 0.7809\n",
      "Epoch 139/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0865 - acc: 0.9606 - val_loss: 0.7473 - val_acc: 0.7550\n",
      "Epoch 140/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0804 - acc: 0.9626 - val_loss: 0.7606 - val_acc: 0.7570\n",
      "Epoch 141/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0862 - acc: 0.9591 - val_loss: 0.8916 - val_acc: 0.7072\n",
      "Epoch 142/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0802 - acc: 0.9606 - val_loss: 0.7931 - val_acc: 0.7430\n",
      "Epoch 143/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0818 - acc: 0.9591 - val_loss: 0.7983 - val_acc: 0.7410\n",
      "Epoch 144/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0821 - acc: 0.9641 - val_loss: 0.8660 - val_acc: 0.7112\n",
      "Epoch 145/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0863 - acc: 0.9606 - val_loss: 0.8330 - val_acc: 0.7331\n",
      "Epoch 146/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0910 - acc: 0.9581 - val_loss: 0.7746 - val_acc: 0.7550\n",
      "Epoch 147/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0756 - acc: 0.9661 - val_loss: 0.7338 - val_acc: 0.7749\n",
      "Epoch 148/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0768 - acc: 0.9681 - val_loss: 0.7919 - val_acc: 0.7450\n",
      "Epoch 149/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0793 - acc: 0.9656 - val_loss: 0.7534 - val_acc: 0.7590\n",
      "Epoch 150/150\n",
      "2005/2005 [==============================] - 2s - loss: 0.0772 - acc: 0.9661 - val_loss: 0.8168 - val_acc: 0.7351\n",
      "Max val_acc: 0.8067729166779385 (step: 13)\n"
     ]
    }
   ],
   "source": [
    "reload(polarity)\n",
    "pd = polarity.PD(w2v, acd_)\n",
    "pd.train_pd_keras(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "\n",
    "# x_train_flat = x_train.reshape(len(x_train), pd.max_sentence_len * 300)\n",
    "# x_test_flat = x_test.reshape(len(x_test), pd.max_sentence_len * 300)\n",
    "\n",
    "# clf = SVC(kernel='rbf', C=15, random_state=1, probability=True)\n",
    "# clf.fit(x_train_flat, y_train)\n",
    "# predictions = clf.predict_proba(x_test_flat)\n",
    "# pd.calc_accuracy(y_test, predictions, clf.classes_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "absa",
   "language": "python",
   "name": "absa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
