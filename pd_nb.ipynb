{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alekseyl\\Envs\\absa\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from importlib import reload\n",
    "from utils import *\n",
    "import test\n",
    "import acd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from jupyterthemes import jtplot\n",
    "# jtplot.style()  # development\n",
    "jtplot.reset()  # production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading real w2v...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "w2v = load_w2v()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer...\n",
      "-- ACD:\n",
      "Loading dataset...\n",
      "Training...\n",
      "Evaluating...\n",
      "F1: 0.7576974564926373\n"
     ]
    }
   ],
   "source": [
    "reload(acd)\n",
    "acd_ = acd.ACD(w2v)\n",
    "acd_.train_acd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import polarity\n",
    "reload(polarity)\n",
    "pd_ = polarity.PD(w2v, acd_)\n",
    "# datasets = pd_.load_grid_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import polarity\n",
    "reload(polarity)\n",
    "pd_ = polarity.PD(w2v, acd_)\n",
    "# pd_.grid_search_pd(datasets, n_jobs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- PD:\n",
      "Loading tokenizer...\n",
      "Loading stemmer...\n",
      "Loading parser...\n",
      "Loading datasets...\n",
      "Core NLP Parser preprocessing result pickled\n",
      "get_pd_ds progress: 0/1708\n",
      "get_pd_ds progress: 100/1708\n",
      "get_pd_ds progress: 200/1708\n",
      "get_pd_ds progress: 300/1708\n",
      "get_pd_ds progress: 400/1708\n",
      "get_pd_ds progress: 500/1708\n",
      "get_pd_ds progress: 600/1708\n",
      "get_pd_ds progress: 700/1708\n",
      "get_pd_ds progress: 800/1708\n",
      "get_pd_ds progress: 900/1708\n",
      "get_pd_ds progress: 1000/1708\n",
      "get_pd_ds progress: 1100/1708\n",
      "get_pd_ds progress: 1200/1708\n",
      "get_pd_ds progress: 1300/1708\n",
      "get_pd_ds progress: 1400/1708\n",
      "get_pd_ds progress: 1500/1708\n",
      "get_pd_ds progress: 1600/1708\n",
      "get_pd_ds progress: 1700/1708\n",
      "Core NLP Parser preprocessing result pickled\n",
      "get_pd_ds progress: 0/587\n",
      "get_pd_ds progress: 100/587\n",
      "get_pd_ds progress: 200/587\n",
      "get_pd_ds progress: 300/587\n",
      "get_pd_ds progress: 400/587\n",
      "get_pd_ds progress: 500/587\n"
     ]
    }
   ],
   "source": [
    "import polarity\n",
    "reload(polarity)\n",
    "pd_ = polarity.PD(w2v, acd_)\n",
    "data = pd_.prepare_data(pd_.get_pd_features_map_tree_distance, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- PD:\n",
      "Loading tokenizer...\n",
      "Loading stemmer...\n",
      "Loading parser...\n",
      "Loading datasets...\n",
      "Core NLP Parser preprocessing result pickled\n",
      "get_pd_ds progress: 0/1708\n",
      "get_pd_ds progress: 100/1708\n",
      "get_pd_ds progress: 200/1708\n",
      "get_pd_ds progress: 300/1708\n",
      "get_pd_ds progress: 400/1708\n",
      "get_pd_ds progress: 500/1708\n",
      "get_pd_ds progress: 600/1708\n",
      "get_pd_ds progress: 700/1708\n",
      "get_pd_ds progress: 800/1708\n",
      "get_pd_ds progress: 900/1708\n",
      "get_pd_ds progress: 1000/1708\n",
      "get_pd_ds progress: 1100/1708\n",
      "get_pd_ds progress: 1200/1708\n",
      "get_pd_ds progress: 1300/1708\n",
      "get_pd_ds progress: 1400/1708\n",
      "get_pd_ds progress: 1500/1708\n",
      "get_pd_ds progress: 1600/1708\n",
      "get_pd_ds progress: 1700/1708\n",
      "Core NLP Parser preprocessing result pickled\n",
      "get_pd_ds progress: 0/587\n",
      "get_pd_ds progress: 100/587\n",
      "get_pd_ds progress: 200/587\n",
      "get_pd_ds progress: 300/587\n",
      "get_pd_ds progress: 400/587\n",
      "get_pd_ds progress: 500/587\n",
      "Train on 2524 samples, validate on 842 samples\n",
      "Epoch 1/300\n",
      "7s - loss: 0.7868 - acc: 0.6842 - val_loss: 0.7471 - val_acc: 0.6853\n",
      "Epoch 2/300\n",
      "6s - loss: 0.6947 - acc: 0.7013 - val_loss: 0.7101 - val_acc: 0.7162\n",
      "Epoch 3/300\n",
      "6s - loss: 0.6573 - acc: 0.7258 - val_loss: 0.6821 - val_acc: 0.7411\n",
      "Epoch 4/300\n",
      "6s - loss: 0.6305 - acc: 0.7433 - val_loss: 0.6634 - val_acc: 0.7399\n",
      "Epoch 5/300\n",
      "6s - loss: 0.6098 - acc: 0.7559 - val_loss: 0.6444 - val_acc: 0.7542\n",
      "Epoch 6/300\n",
      "6s - loss: 0.5945 - acc: 0.7647 - val_loss: 0.6277 - val_acc: 0.7613\n",
      "Epoch 7/300\n",
      "6s - loss: 0.5791 - acc: 0.7738 - val_loss: 0.6157 - val_acc: 0.7684\n",
      "Epoch 8/300\n",
      "6s - loss: 0.5667 - acc: 0.7789 - val_loss: 0.6029 - val_acc: 0.7672\n",
      "Epoch 9/300\n",
      "6s - loss: 0.5557 - acc: 0.7880 - val_loss: 0.5987 - val_acc: 0.7850\n",
      "Epoch 10/300\n",
      "6s - loss: 0.5481 - acc: 0.7932 - val_loss: 0.5837 - val_acc: 0.7755\n",
      "Epoch 11/300\n",
      "6s - loss: 0.5387 - acc: 0.7924 - val_loss: 0.5769 - val_acc: 0.7732\n",
      "Epoch 12/300\n",
      "6s - loss: 0.5310 - acc: 0.7979 - val_loss: 0.5690 - val_acc: 0.7850\n",
      "Epoch 13/300\n",
      "6s - loss: 0.5238 - acc: 0.8023 - val_loss: 0.5618 - val_acc: 0.7850\n",
      "Epoch 14/300\n"
     ]
    }
   ],
   "source": [
    "import polarity\n",
    "reload(polarity)\n",
    "pd_ = polarity.PD(w2v, acd_)\n",
    "pd_.train_pd_keras_both(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "absa",
   "language": "python",
   "name": "absa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
