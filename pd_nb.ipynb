{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alekseyl\\Envs\\absa\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "from utils import *\n",
    "import test\n",
    "import polarity\n",
    "import acd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading real w2v...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "w2v = load_w2v()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- ACD:\n",
      "Loading tokenizer...\n",
      "Loading stemmer...\n",
      "Loading dataset...\n",
      "Training...\n",
      "Evaluating...\n",
      "F1: {'f1': 0.7287917737789202, 'precision': 0.6974169741697417, 'recall': 0.7631224764468372, 'tp': 567, 'fp': 246, 'fn': 176}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alekseyl\\Envs\\absa\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:563: ConvergenceWarning: Stochastic Optimizer: Maximum iterations reached and the optimization hasn't converged yet.\n",
      "  % (), ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "reload(acd)\n",
    "acd_ = acd.ACD(w2v)\n",
    "acd_.train_acd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- PD:\n",
      "Loading tokenizer...\n",
      "Loading stemmer...\n",
      "Loading parser...\n",
      "Loading datasets...\n",
      "Core NLP Parser preprocessing...\n",
      "get_pd_ds progress: 0/1708\n",
      "get_pd_ds progress: 100/1708\n",
      "get_pd_ds progress: 200/1708\n",
      "get_pd_ds progress: 300/1708\n",
      "get_pd_ds progress: 400/1708\n",
      "get_pd_ds progress: 500/1708\n",
      "get_pd_ds progress: 600/1708\n",
      "get_pd_ds progress: 700/1708\n",
      "get_pd_ds progress: 800/1708\n",
      "get_pd_ds progress: 900/1708\n",
      "get_pd_ds progress: 1000/1708\n",
      "get_pd_ds progress: 1100/1708\n",
      "get_pd_ds progress: 1200/1708\n",
      "get_pd_ds progress: 1300/1708\n",
      "get_pd_ds progress: 1400/1708\n",
      "get_pd_ds progress: 1500/1708\n",
      "get_pd_ds progress: 1600/1708\n",
      "get_pd_ds progress: 1700/1708\n",
      "Core NLP Parser preprocessing...\n",
      "get_pd_ds progress: 0/587\n",
      "get_pd_ds progress: 100/587\n",
      "get_pd_ds progress: 200/587\n",
      "get_pd_ds progress: 300/587\n",
      "get_pd_ds progress: 400/587\n",
      "get_pd_ds progress: 500/587\n"
     ]
    }
   ],
   "source": [
    "reload(polarity)\n",
    "pd = polarity.PD(w2v, acd_)\n",
    "data = pd.prepare_data(pd.get_pd_features_map_tree_distance, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2507 samples, validate on 859 samples\n",
      "Epoch 1/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.9081 - acc: 0.5876 - val_loss: 0.7470 - val_acc: 0.7253\n",
      "Epoch 2/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.7397 - acc: 0.6721 - val_loss: 0.6818 - val_acc: 0.7346\n",
      "Epoch 3/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.7022 - acc: 0.6849 - val_loss: 0.6598 - val_acc: 0.7555\n",
      "Epoch 4/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.6688 - acc: 0.7020 - val_loss: 0.6301 - val_acc: 0.7648\n",
      "Epoch 5/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.6285 - acc: 0.7304 - val_loss: 0.5940 - val_acc: 0.7765\n",
      "Epoch 6/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.5898 - acc: 0.7511 - val_loss: 0.5825 - val_acc: 0.7788\n",
      "Epoch 7/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.5515 - acc: 0.7886 - val_loss: 0.5749 - val_acc: 0.7963\n",
      "Epoch 8/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.5182 - acc: 0.8073 - val_loss: 0.5440 - val_acc: 0.8172\n",
      "Epoch 9/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.4899 - acc: 0.8241 - val_loss: 0.5066 - val_acc: 0.8079\n",
      "Epoch 10/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.4640 - acc: 0.8428 - val_loss: 0.4974 - val_acc: 0.8219\n",
      "Epoch 11/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.4419 - acc: 0.8512 - val_loss: 0.5003 - val_acc: 0.8277\n",
      "Epoch 12/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.4247 - acc: 0.8596 - val_loss: 0.4826 - val_acc: 0.8393\n",
      "Epoch 13/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.4024 - acc: 0.8672 - val_loss: 0.4725 - val_acc: 0.8405\n",
      "Epoch 14/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.3901 - acc: 0.8688 - val_loss: 0.4626 - val_acc: 0.8370\n",
      "Epoch 15/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.3735 - acc: 0.8740 - val_loss: 0.4566 - val_acc: 0.8335\n",
      "Epoch 16/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.3582 - acc: 0.8791 - val_loss: 0.4519 - val_acc: 0.8300\n",
      "Epoch 17/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.3434 - acc: 0.8847 - val_loss: 0.4552 - val_acc: 0.8428\n",
      "Epoch 18/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.3322 - acc: 0.8855 - val_loss: 0.4526 - val_acc: 0.8452\n",
      "Epoch 19/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.3193 - acc: 0.8891 - val_loss: 0.4645 - val_acc: 0.8359\n",
      "Epoch 20/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.3077 - acc: 0.8923 - val_loss: 0.4459 - val_acc: 0.8463\n",
      "Epoch 21/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.2985 - acc: 0.8959 - val_loss: 0.4462 - val_acc: 0.8498\n",
      "Epoch 22/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.2869 - acc: 0.9023 - val_loss: 0.4401 - val_acc: 0.8475\n",
      "Epoch 23/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.2760 - acc: 0.9067 - val_loss: 0.5143 - val_acc: 0.8021\n",
      "Epoch 24/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.2673 - acc: 0.9071 - val_loss: 0.4853 - val_acc: 0.8231\n",
      "Epoch 25/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.2565 - acc: 0.9150 - val_loss: 0.4412 - val_acc: 0.8510\n",
      "Epoch 26/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.2441 - acc: 0.9154 - val_loss: 0.4386 - val_acc: 0.8417\n",
      "Epoch 27/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.2344 - acc: 0.9178 - val_loss: 0.4419 - val_acc: 0.8498\n",
      "Epoch 28/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.2296 - acc: 0.9182 - val_loss: 0.4986 - val_acc: 0.8231\n",
      "Epoch 29/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.2236 - acc: 0.9238 - val_loss: 0.4511 - val_acc: 0.8533\n",
      "Epoch 30/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.2121 - acc: 0.9222 - val_loss: 0.4440 - val_acc: 0.8440\n",
      "Epoch 31/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.2061 - acc: 0.9214 - val_loss: 0.4673 - val_acc: 0.8254\n",
      "Epoch 32/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.1997 - acc: 0.9254 - val_loss: 0.4496 - val_acc: 0.8370\n",
      "Epoch 33/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.1943 - acc: 0.9294 - val_loss: 0.4881 - val_acc: 0.8289\n",
      "Epoch 34/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.1857 - acc: 0.9310 - val_loss: 0.4508 - val_acc: 0.8545\n",
      "Epoch 35/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.1821 - acc: 0.9322 - val_loss: 0.4515 - val_acc: 0.8440\n",
      "Epoch 36/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.1764 - acc: 0.9302 - val_loss: 0.4964 - val_acc: 0.8300\n",
      "Epoch 37/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.1713 - acc: 0.9386 - val_loss: 0.4533 - val_acc: 0.8522\n",
      "Epoch 38/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.1639 - acc: 0.9406 - val_loss: 0.4585 - val_acc: 0.8533\n",
      "Epoch 39/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.1617 - acc: 0.9390 - val_loss: 0.4535 - val_acc: 0.8487\n",
      "Epoch 40/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.1542 - acc: 0.9406 - val_loss: 0.4924 - val_acc: 0.8370\n",
      "Epoch 41/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.1521 - acc: 0.9402 - val_loss: 0.4615 - val_acc: 0.8428\n",
      "Epoch 42/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.1438 - acc: 0.9422 - val_loss: 0.4769 - val_acc: 0.8428\n",
      "Epoch 43/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.1429 - acc: 0.9418 - val_loss: 0.4675 - val_acc: 0.8452\n",
      "Epoch 44/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.1377 - acc: 0.9450 - val_loss: 0.4695 - val_acc: 0.8522\n",
      "Epoch 45/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.1340 - acc: 0.9489 - val_loss: 0.4654 - val_acc: 0.8463\n",
      "Epoch 46/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.1331 - acc: 0.9458 - val_loss: 0.5443 - val_acc: 0.8277\n",
      "Epoch 47/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.1258 - acc: 0.9517 - val_loss: 0.5292 - val_acc: 0.8312\n",
      "Epoch 48/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.1212 - acc: 0.9537 - val_loss: 0.4883 - val_acc: 0.8393\n",
      "Epoch 49/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.1208 - acc: 0.9549 - val_loss: 0.5416 - val_acc: 0.8324\n",
      "Epoch 50/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.1234 - acc: 0.9537 - val_loss: 0.4861 - val_acc: 0.8463\n",
      "Epoch 51/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.1141 - acc: 0.9521 - val_loss: 0.4785 - val_acc: 0.8533\n",
      "Epoch 52/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.1096 - acc: 0.9569 - val_loss: 0.4968 - val_acc: 0.8556\n",
      "Epoch 53/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.1091 - acc: 0.9561 - val_loss: 0.4852 - val_acc: 0.8510\n",
      "Epoch 54/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.1090 - acc: 0.9581 - val_loss: 0.4847 - val_acc: 0.8522\n",
      "Epoch 55/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.1024 - acc: 0.9613 - val_loss: 0.4917 - val_acc: 0.8475\n",
      "Epoch 56/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.1045 - acc: 0.9585 - val_loss: 0.5172 - val_acc: 0.8359\n",
      "Epoch 57/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.1015 - acc: 0.9561 - val_loss: 0.5146 - val_acc: 0.8475\n",
      "Epoch 58/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.1056 - acc: 0.9561 - val_loss: 0.5057 - val_acc: 0.8533\n",
      "Epoch 59/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0990 - acc: 0.9621 - val_loss: 0.5018 - val_acc: 0.8545\n",
      "Epoch 60/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.1006 - acc: 0.9565 - val_loss: 0.4992 - val_acc: 0.8463\n",
      "Epoch 61/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0963 - acc: 0.9585 - val_loss: 0.5835 - val_acc: 0.8254\n",
      "Epoch 62/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0963 - acc: 0.9577 - val_loss: 0.5076 - val_acc: 0.8522\n",
      "Epoch 63/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.0911 - acc: 0.9617 - val_loss: 0.5088 - val_acc: 0.8487\n",
      "Epoch 64/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0946 - acc: 0.9613 - val_loss: 0.4913 - val_acc: 0.8510\n",
      "Epoch 65/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0886 - acc: 0.9641 - val_loss: 0.5152 - val_acc: 0.8533\n",
      "Epoch 66/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.0963 - acc: 0.9565 - val_loss: 0.5396 - val_acc: 0.8452\n",
      "Epoch 67/100\n",
      "2507/2507 [==============================] - 4s - loss: 0.0896 - acc: 0.9605 - val_loss: 0.5067 - val_acc: 0.8475\n",
      "Epoch 68/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0959 - acc: 0.9549 - val_loss: 0.5334 - val_acc: 0.8475\n",
      "Epoch 69/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0914 - acc: 0.9597 - val_loss: 0.5326 - val_acc: 0.8440\n",
      "Epoch 70/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0847 - acc: 0.9677 - val_loss: 0.5318 - val_acc: 0.8545\n",
      "Epoch 71/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0866 - acc: 0.9629 - val_loss: 0.5212 - val_acc: 0.8533\n",
      "Epoch 72/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0876 - acc: 0.9617 - val_loss: 0.5250 - val_acc: 0.8510\n",
      "Epoch 73/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0837 - acc: 0.9645 - val_loss: 0.5485 - val_acc: 0.8463\n",
      "Epoch 74/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0859 - acc: 0.9633 - val_loss: 0.5241 - val_acc: 0.8545\n",
      "Epoch 75/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0868 - acc: 0.9625 - val_loss: 0.5209 - val_acc: 0.8556\n",
      "Epoch 76/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0902 - acc: 0.9593 - val_loss: 0.5287 - val_acc: 0.8568\n",
      "Epoch 77/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0820 - acc: 0.9657 - val_loss: 0.5384 - val_acc: 0.8522\n",
      "Epoch 78/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0802 - acc: 0.9641 - val_loss: 0.5367 - val_acc: 0.8568\n",
      "Epoch 79/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0827 - acc: 0.9629 - val_loss: 0.5352 - val_acc: 0.8545\n",
      "Epoch 80/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0875 - acc: 0.9581 - val_loss: 0.5837 - val_acc: 0.8393\n",
      "Epoch 81/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0810 - acc: 0.9621 - val_loss: 0.5655 - val_acc: 0.8417\n",
      "Epoch 82/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0792 - acc: 0.9641 - val_loss: 0.5349 - val_acc: 0.8545\n",
      "Epoch 83/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0874 - acc: 0.9605 - val_loss: 0.5423 - val_acc: 0.8475\n",
      "Epoch 84/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0815 - acc: 0.9649 - val_loss: 0.5303 - val_acc: 0.8533\n",
      "Epoch 85/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0805 - acc: 0.9669 - val_loss: 0.5562 - val_acc: 0.8568\n",
      "Epoch 86/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0796 - acc: 0.9637 - val_loss: 0.5486 - val_acc: 0.8522\n",
      "Epoch 87/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0806 - acc: 0.9641 - val_loss: 0.5569 - val_acc: 0.8487\n",
      "Epoch 88/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0782 - acc: 0.9637 - val_loss: 0.5626 - val_acc: 0.8428\n",
      "Epoch 89/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0759 - acc: 0.9669 - val_loss: 0.5902 - val_acc: 0.8417\n",
      "Epoch 90/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0786 - acc: 0.9677 - val_loss: 0.5580 - val_acc: 0.8498\n",
      "Epoch 91/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0831 - acc: 0.9641 - val_loss: 0.6284 - val_acc: 0.8289\n",
      "Epoch 92/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0755 - acc: 0.9673 - val_loss: 0.5779 - val_acc: 0.8428\n",
      "Epoch 93/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0780 - acc: 0.9677 - val_loss: 0.5509 - val_acc: 0.8545\n",
      "Epoch 94/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0777 - acc: 0.9661 - val_loss: 0.5776 - val_acc: 0.8463\n",
      "Epoch 95/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0796 - acc: 0.9669 - val_loss: 0.6210 - val_acc: 0.8324\n",
      "Epoch 96/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0761 - acc: 0.9677 - val_loss: 0.5804 - val_acc: 0.8417\n",
      "Epoch 97/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0821 - acc: 0.9645 - val_loss: 0.5599 - val_acc: 0.8510\n",
      "Epoch 98/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0799 - acc: 0.9629 - val_loss: 0.5915 - val_acc: 0.8428\n",
      "Epoch 99/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0774 - acc: 0.9633 - val_loss: 0.5985 - val_acc: 0.8440\n",
      "Epoch 100/100\n",
      "2507/2507 [==============================] - 5s - loss: 0.0797 - acc: 0.9641 - val_loss: 0.5759 - val_acc: 0.8452\n",
      "Max val_acc: 0.8568102391274067 (epoch: 76)\n"
     ]
    }
   ],
   "source": [
    "reload(polarity)\n",
    "pd = polarity.PD(w2v, acd_)\n",
    "pd.train_pd_keras(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.svm import SVC\n",
    "\n",
    "# x_train_flat = x_train.reshape(len(x_train), pd.max_sentence_len * 300)\n",
    "# x_test_flat = x_test.reshape(len(x_test), pd.max_sentence_len * 300)\n",
    "\n",
    "# clf = SVC(kernel='rbf', C=15, random_state=1, probability=True)\n",
    "# clf.fit(x_train_flat, y_train)\n",
    "# predictions = clf.predict_proba(x_test_flat)\n",
    "# pd.calc_accuracy(y_test, predictions, clf.classes_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "absa",
   "language": "python",
   "name": "absa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
